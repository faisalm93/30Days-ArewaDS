          #Exercises: Day 20
 #Q1. Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'

 
 import requests
import re
import collections

# Get the content of the URL
url = 'http://www.gutenberg.org/files/1112/1112.txt'
response = requests.get(url)
text = response.content.decode('utf-8')
#  we re decoding the bytes content into a Unicode string using the UTF-8 encoding to avoid issues  when working with non-ASCII characters commonly found in languages other than english.

# Remove unwanted characters from the text using regular expressions
text = re.sub('[^a-zA-Z]', ' ', text)

# Convert the text to lowercase and split it into words
words = text.lower().split()

# Count the frequency of each word using collections.Counter
word_counts = collections.Counter(words)

# Get the 10 most frequent words
top_words = word_counts.most_common(10)

# Print the top 10 words and their frequencies
for word, count in top_words:
    print(word, count)


#Q2. Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find: the min, max, mean, median, standard deviation of cats' weight in metric units.
the min, max, mean, median, standard deviation of cats' lifespan in years.Create a frequency table of country and breed of cats


import requests
import statistics
import pandas as pd

# Get the JSON data from the API
cats_api = 'https://api.thecatapi.com/v1/breeds'
response = requests.get(cats_api)
data = response.json()

# Extract the weight and lifespan data for each breed of cat
weights = []
lifespans = []
for cat in data:
    weight = cat['weight']['metric'].split()[0]
    lifespan = cat.get('life_span', None)
    if weight != 'Unknown' and lifespan is not None:
        weights.append(float(weight))
        lifespans.append(int(lifespan.split()[0]))

# Convert the weight data to metric units
weights = [w / 1000 for w in weights]

# Calculate the min, max, mean, median, and standard deviation of the weight and lifespan data
weight_min = min(weights)
weight_max = max(weights)
weight_mean = statistics.mean(weights)
weight_median = statistics.median(weights)
weight_stdev = statistics.stdev(weights)

lifespan_min = min(lifespans)
lifespan_max = max(lifespans)
lifespan_mean = statistics.mean(lifespans)
lifespan_median = statistics.median(lifespans)
lifespan_stdev = statistics.stdev(lifespans)

print("Weight in kg - min: {:.2f}, max: {:.2f}, mean: {:.2f}, median: {:.2f}, stdev: {:.2f}".format(weight_min, weight_max, weight_mean, weight_median, weight_stdev))
print("Lifespan in years - min: {}, max: {}, mean: {:.2f}, median: {:.2f}, stdev: {:.2f}".format(lifespan_min, lifespan_max, lifespan_mean, lifespan_median, lifespan_stdev))

# Create a pandas DataFrame from the JSON data and group the breeds by country to create the frequency table
df = pd.DataFrame(data)
freq_table = df.groupby('origin').breed.count().reset_index()
print(freq_table)

#Q3. Read the countries API and find the 10 largest countries, the 10 most spoken languages and the total number of languages in the countries API


import requests

# Get the JSON data from the API
countries_api = 'https://restcountries.com/v2/all'
response = requests.get(countries_api)
data = response.json()

# Extract the population and name data for each country
populations = []
names = []
for country in data:
    population = country['population']
    name = country['name']
    populations.append(population)
    names.append(name)

# Find the 10 largest countries by population
largest_countries = sorted(zip(names, populations), key=lambda x: x[1], reverse=True)[:10]
print("The 10 largest countries by population are:")
for country in largest_countries:
    print(country[0])

# Extract the languages data for each country
languages = []
for country in data:
    for language in country['languages']:
        languages.append(language['name'])

# Find the 10 most spoken languages
most_spoken_languages = sorted(set(languages), key=languages.count, reverse=True)[:10]
print("The 10 most spoken languages are:")
for language in most_spoken_languages:
    print(language)

# Find the total number of languages in the countries API
total_languages = len(set(languages))
print("The total number of languages in the countries API is:", total_languages)

#Q4. UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4

import requests
from bs4 import BeautifulSoup

# Fetch the webpage
url = 'https://archive.ics.uci.edu/ml/datasets.php'
response = requests.get(url)

# Parse the HTML content
soup = BeautifulSoup(response.content, 'html.parser')

# Find the page title
title = soup.title.string

# Print the page title
print(title)


